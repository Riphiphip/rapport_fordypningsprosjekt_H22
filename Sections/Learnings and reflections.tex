\section{Learnings and reflections} \label{sec:learnings}
This project has been about figuring out how, and if, RVSDG could be implemented in MLIR. Figuring out how MLIR itself works has been a major part of that. Since I had no idea what I was doing going into the project, this section will be covering some of the major choices I made and whether they helped or hindered me in the long run.

\subsection{Evaluating representations}
Working on this project has made it clear that RVSDG and MLIR should be a pretty good fit. The available tools and representations in MLIR lend themselves nicely to represent RVSDG, although the particular ways I chose to use them may not have been optimal. In particular, I think the representation I chose for region arguments needs to be changed. The way this was solved for the gamma-node does unfortunately not map to most of the other nodes \hyperref[sec:chosen-representations]{as was discussed earlier}. A better, hopefully more scalable solution to this problem is to use MLIR's concept of block arguments. Ops representing structural RVSDG nodes could ensure that their regions only contain a single block with MLIR arguments that map directly to RVSDG arguments. Using this with the already established representation of using block terminator Ops to take results would make the whole representation quite cohesive and should work nicely with all the structural nodes.

\subsection{Project structure}
The structure of a project is important for efficient development. Unfortunately it's not always apparent how to best structure a project until development is well on the way. While working on the project there were several times where I felt that my initial choice of project structure was slowing me down. While there were probably more factors at play, here are some MLIR specific ones I noticed.

%Evaluate in-tree vs standalone
\subsubsection{In-tree vs standalone} \label{sec:learnings:in-tree-vs-standalone}
My choice of making an in-tree dialect may have been a mistake. During development, I spent a lot of time simply navigating the source tree. There were also several instances where I had to modify core MLIR files to make the RVSDG dialect build and integrate with the rest of MLIR. To properly track these changes, I had to make a custom fork of LLVM. Since I was not only adding my own files, it would also make it harder to use the RVSDG dialect with a newer LLVM version since there is almost guaranteed to be merge conflicts. On the other hand, starting off with an in-tree dialect provided a lot of examples for how to set up the build system and how to get everything registered in the right places. In conclusion, I think an in-tree dialect is a good place to start to get familiar with the concepts of MLIR, but I will probably migrate my dialect to a standalone structure now that I have an idea of how things work. Doing this should also decrease incremental build times as MLIR itself does not have to be rebuilt, only linked in.

%TableGen vs C++ templates: Is it worth it?
\subsubsection{TableGen}
The use of TableGen to define Op and dialect properties was a large source of friction while working. The lack of good development tools for TableGen meant that finding correct field names and ensuring that classes were correctly integrated with each other was quite slow. Later versions of MLIR attempt to solve this issue by including a language server for TableGen specifications \cite{mlir_language_server}. Unfortunately, using this was not an option for me since the version I worked on only comes with a language server for MLIR assembly files, and MLIR does not provide standalone versions of the other language servers. Having access to this language server would allow my IDE to provide quick access to documentation and faster navigation, both of which would be significant quality of life improvements. 

Writing the TableGen definitions themselves was however not the main issue I faced when using TableGen. The TableGen definitions are used to generate several C++ source and header files. The header files contain C++ class definitions for the dialect, Ops, and types, while the source files contain default implementations of several methods for the same classes. The source files also need to be explicitly built by the dialect author. This is where the problem occurs. The auto-generated source files use several MLIR classes and types, but they do not include the appropriate header files to access these. Figuring out exactly which header files to include where to allow these auto-generated files to even build ended up being a massive time sink. In the end, the solution I came up with was to scrape includes from similar files from other dialects until the build passed. Then each include was removed, and the compilation was run again. If it still worked, the include stayed out. If it failed, it was added back in. By the end, I felt like I had a decent idea of which headers were required to include for the auto-generated Op-sources, but I have yet to figure it out for types.

I will admit that I was sceptical towards TableGen from the beginning, and I considered abandoning it when the previously mentioned problems became clear to me. Now, however, I don't think I will be moving away from TableGen. I noticed that once the definitions were properly set up they were extremely easy to modify, and those changes propagated through the project quite nicely. It also helped maintain a uniform access API across different Ops. In the end, TableGen served its purpose as a single source of truth surprisingly well. 

%Ways to speed up development?

While it would be nice to have a way to make the learning curve for TableGen a little smoother, I don't think there are any great options for achieving that. The first thing I would try is to use a newer MLIR version to get access to the TableGen language server. Getting a little bit of auto-completion and fast navigation could make the process of figuring out what goes where slightly less painful. Another thing that would be helpful is to automatically include the header files required for the auto-generated c++ source files that are produced by TableGen. This would probably have to be implemented as a part of the file generation and might have other unintended consequences. A more realistic option is probably to document which features require which headers. This documentation would have to be extremely easy to find and navigate to be useful. Spending some time early on to learn TableGen by itself might also be a good idea for new developers.
